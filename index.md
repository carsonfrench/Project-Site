## Poster Generator
Chloe, David, Nate, Carson, and Pei Pei

### Project Description

We want to create a GAN to generate movie posters, investigating if a neural network can create visually interesting and convincing art that we can use to decorate our dorms. 

This problem is hard because movie posters are usually focused on cohesive designs that center around a few important objects, whereas recently created generative art struggles with emphasis around clearly recognizable elements, instead focusing on emulating stylistic aspects of different genres.

We intend to experiment with specific styles of posters in order to generate designs that are visually appealing and use graphic design principles instead of just throwing a bunch of objects together.

We will most likely face many technical challenges. Right now one major challenge is finding a good dataset for posters.

Our results will hopefully generate decent looking posters and contribute to discourse about the role of AI in art and design.

Ethical implications: 
If we train an AI to generate posters based on existing movie posters, it raises the question of where credit should be given - is the AI artist responsible for the work? Furthermore, how close the results are to the training sets could result in plagiarism, and would the subsequent responsibilities lie on the AI or the creators?

### Related Literature

1. [CAN: Creative Adversarial Networks, Generating "Art" by Learning About Styles and Deviating from Style Norms](https://arxiv.org/abs/1706.07068)

    This paper discusses a new technique to create AI-generated art, by modifying a GAN to what the authors call a CAN (Creative Adversarial Network). This network tries to make art that innovated by blurring style classifications, but not by too much.

2. [A State-of-the-Art Review on Image Synthesis With Generative Adversarial Networks](https://ieeexplore.ieee.org/abstract/document/9043519)

    This paper provides an overview of recent research about GANs and its current applications in the field of image processing. It discusses different methods used in GAN applications and how these methods have affected the performance of image generation. Finally, it discusses different problems one might face when training and evaluating GANs, and it offers insight into future applications of GANs.

3. [A survey of image synthesis and editing with generative adversarial networks](https://ieeexplore.ieee.org/abstract/document/8195348)

    This paper summarizes the different uses of General Adversarial Networks. GANs consist of a generator network which creates images and a discriminator network that determines if the image can be considered real or fake. They can be used to modify an existing image or create new images from a text input. Although basic GANs can create realistic images it is still difficult to generate high resolution images as well as video and 3D models.

4. [Visual Indeterminacy in GAN Art](https://direct.mit.edu/leon/article/53/4/424/96926/Visual-Indeterminacy-in-GAN-Art)

    The author tackles the topic of visual indeterminacy in GAN art - the quality of images to appear real, but upon looking closer, are actually composed of elements that are unrecognizable. Many artworks generated by GAN models have details that can look real, such as human arms or tall skyscrapers, yet these details are not resolved fully and blend ambiguously into the background or into other objects. The author believes that this indeterminacy stems from imperfect generative models, as GANs at the moment are only capable of combining objects, textures, and backgrounds in an "uncanny valley" manner; models are not yet able to generate new compositions of these elements, and as a result, must rely on training images with similar, existing compositions. Subsequently, the resulting images are almost realistic, but fail to achieve certainty. Moving forward, the paper suggests conducting more research into vision neuroscience models and cortical modeling to better understand how visual indeterminacy can be manipulated in GAN artworks.

5. [Modeling Artistic Workflows for Image Generation and Editing](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123630154.pdf)

    The authors of the paper propose a model that generates images in a given art style at multiple steps in the image creation process with the intention of revamping the process of creating art. The authors also introduce a new loss optimization method that works well for this use case of GANS.
    
### Project Update 1

- Name and link to the software you will use (or state that you are writing something from scratch).
    - [PyTorch](https://pytorch.org/) (use to make a GAN)
- Name and link to the dataset that you will be using (or state how you will create your own dataset).
    - [41K movie posters from IMDB](https://www.kaggle.com/dadajonjurakuziev/movieposter)
- Provide a high-level overview of the following:
    - The type of neural network you will use (e.g., fully connected, convolutional, recurrent, etc.)
      
      Deep Convolutional Generative Adversarial Network
    - The shape and type of your inputs (are they three-channel images? sequences of words? a vector of floating-point values? embeddings? etc.)

    -Training input: three-channel poster images
    - Shape of single input: (3, 386, 256)
    
    3 = number of channels
    
    386 = height in px
    
    256 = width in px

    (if there are images in a different resolution, we will rescale them)
    
    Generation input: random noise

    May potentially add an extra variable, i.e. genre, and change our network to a conditional GAN 

- The shape and type of your outputs (are you performing classification? regression? segmentation?, etc.)
    - We are outputting three-channel images, shape(3, 386, 256)


